{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File paths handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change if data location is different\n",
    "\n",
    "base_path = \"../../KArSL-100/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_label_map(excel_path):\n",
    "    df = pd.read_excel(excel_path)\n",
    "    sign_ids = df['SignID'].astype(str).str.zfill(4)\n",
    "    label_map = {sid: idx for idx, sid in enumerate(sign_ids)}\n",
    "    signid_map = {idx: sid for idx, sid in enumerate(sign_ids)}\n",
    "    return label_map, signid_map\n",
    "label_map, signid_map = load_label_map(os.path.join(base_path, \"KARSL-100_Labels.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_sign_id(folder_name):\n",
    "    # folder like \"03_03_1234_(15_12_16_16_11_06)_c\"\n",
    "    parts = folder_name.split('_')\n",
    "    return parts[2]  # the 4-digit sign ID\n",
    "\n",
    "def load_sequence(sequence_path):\n",
    "    frames = sorted([\n",
    "        f for f in os.listdir(sequence_path) if f.endswith('.jpg')\n",
    "    ])\n",
    "    sequence = []\n",
    "    for frame in frames:\n",
    "        img_path = os.path.join(sequence_path, frame)\n",
    "        img = image.load_img(img_path, target_size=(128, 128))\n",
    "  # Resize if needed\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        sequence.append(img_array)\n",
    "    return np.array(sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SignLanguageGenerator(Sequence):\n",
    "    def __init__(self, samples, label_map, batch_size=6, max_frames=20, input_size=(128, 128)):\n",
    "        self.samples = samples\n",
    "        self.label_map = label_map\n",
    "        self.batch_size = batch_size\n",
    "        self.max_frames = max_frames\n",
    "        self.input_size = input_size\n",
    "        random.shuffle(self.samples)\n",
    "\n",
    "    def _load_samples(self):\n",
    "        samples = []\n",
    "        for sign_id in os.listdir(self.data_dir):\n",
    "            sign_path = os.path.join(self.data_dir, sign_id)\n",
    "            if not os.path.isdir(sign_path):\n",
    "                continue\n",
    "            for repetition_folder in os.listdir(sign_path):\n",
    "                if not os.path.isdir(os.path.join(sign_path, repetition_folder)):\n",
    "                    continue\n",
    "                samples.append((sign_id, os.path.join(sign_path, repetition_folder)))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.samples) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_samples = self.samples[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_frames = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for sign_id, folder_path in batch_samples:\n",
    "            frames = self._load_frames(folder_path)\n",
    "            batch_frames.append(frames)\n",
    "            batch_labels.append(self.label_map[sign_id])\n",
    "\n",
    "        batch_frames = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            batch_frames, padding='post', maxlen=self.max_frames, dtype='float32'\n",
    "        )\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=len(self.label_map))\n",
    "        return np.array(batch_frames), np.array(batch_labels)\n",
    "\n",
    "    def _load_frames(self, folder_path):\n",
    "        frame_files = sorted([\n",
    "            f for f in os.listdir(folder_path) if f.endswith('.jpg') or f.endswith('.png')\n",
    "        ])[:self.max_frames]\n",
    "\n",
    "        frames = []\n",
    "        for f in frame_files:\n",
    "            img_path = os.path.join(folder_path, f)\n",
    "            img = image.load_img(img_path, target_size=self.input_size)\n",
    "            img = image.img_to_array(img) / 255.0\n",
    "            frames.append(img)\n",
    "\n",
    "        return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function for getting file paths\n",
    "\n",
    "def get_samples(path):\n",
    "    all_samples = []\n",
    "    for sign_id in os.listdir(path):  \n",
    "        sign_path = os.path.join(path, sign_id)\n",
    "        if not os.path.isdir(sign_path):\n",
    "            continue\n",
    "        for repetition_folder in os.listdir(sign_path):\n",
    "            if not os.path.isdir(os.path.join(sign_path, repetition_folder)):\n",
    "                continue\n",
    "            all_samples.append((sign_id, os.path.join(sign_path, repetition_folder)))\n",
    "    return all_samples\n",
    "\n",
    "\n",
    "train_dir = os.path.join(base_path, 'train')\n",
    "test_dir = os.path.join(base_path, 'test')\n",
    "train_samples = get_samples(train_dir)\n",
    "test_samples = get_samples(test_dir)\n",
    "\n",
    "# Split into train/val\n",
    "train_samples, valid_samples = train_test_split(train_samples, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data generators\n",
    "\n",
    "train_gen = SignLanguageGenerator(train_samples, label_map, max_frames=30)\n",
    "valid_gen = SignLanguageGenerator(valid_samples, label_map, max_frames=30)\n",
    "test_gen = SignLanguageGenerator(test_samples, label_map,  max_frames=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, (X, y) = next(enumerate(train_gen))\n",
    "print(signid_map[np.argmax(y[1])])\n",
    "plt.imshow(X[1][29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.argmax(model.predict(X), axis=1))\n",
    "print(np.argmax(y, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import TimeDistributed, GRU, Dense, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Change input shape when changing frame width and height\n",
    "input_shape = (30, 128, 128, 3)\n",
    "num_classes = 100\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Load MobileNet \n",
    "mobilenet_base = MobileNet(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze mobilenet layers (to fine-tune later if you want)\n",
    "for layer in mobilenet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Apply MobileNet to each frame individually using TimeDistributed\n",
    "x = TimeDistributed(mobilenet_base)(inputs)\n",
    "x = TimeDistributed(GlobalAveragePooling2D())(x)  # (batch, timesteps, features)\n",
    "\n",
    "# RNN layer (you can choose LSTM, GRU, etc.)\n",
    "x = GRU(128, return_sequences=False)(x)  # (batch, 256)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_gen, validation_data=valid_gen, epochs=10, verbose=1, callbacks=[es])\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_gen)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"100_labels_model_128x128_30_frames.keras\")\n",
    "loaded_model = load_model(\"100_labels_model_128x128_30_frames.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (X, y) = next(enumerate(test_gen))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict(X)\n",
    "print(f\"True: {np.argmax(y, axis=1)}\\nPred: {np.argmax(prediction, axis=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "myenv",
   "name": "tf2-gpu.2-17.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-17:m128"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7221608,
     "sourceId": 11515637,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (ASLT) (Local)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
